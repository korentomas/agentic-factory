name: Agent Review

# Triggers on any PR targeting main from a branch named agent/*
# Only reviews agent-written PRs â€” human PRs are unaffected.

on:
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]

jobs:
  # â”€â”€ Gate: only run on agent/* branches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  check-branch:
    name: "Check: Agent Branch"
    runs-on: ubuntu-latest
    outputs:
      is_agent_pr: ${{ steps.check.outputs.is_agent_pr }}
    steps:
      - name: Is this an agent PR?
        id: check
        run: |
          if [[ "${{ github.head_ref }}" == agent/* ]]; then
            echo "is_agent_pr=true" >> "$GITHUB_OUTPUT"
            echo "Agent PR detected: ${{ github.head_ref }}"
          else
            echo "is_agent_pr=false" >> "$GITHUB_OUTPUT"
            echo "Not an agent PR â€” skipping review"
          fi

  # â”€â”€ Step 1: Risk policy gate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  risk-gate:
    name: "Gate: Risk Policy"
    needs: check-branch
    if: needs.check-branch.outputs.is_agent_pr == 'true'
    runs-on: ubuntu-latest
    outputs:
      tier: ${{ steps.gate.outputs.tier }}
      required_checks: ${{ steps.gate.outputs.required_checks }}
      blocked: ${{ steps.gate.outputs.blocked }}
    steps:
      - name: Generate GitHub App token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Run risk policy gate
        id: gate
        run: |
          # Get changed files vs base branch
          CHANGED_FILES=$(git diff --name-only "origin/${{ github.base_ref }}...HEAD" | tr '\n' ' ')
          echo "Changed files: $CHANGED_FILES"

          # Run the gate script
          python scripts/risk_policy_gate.py \
            --changed-files "$CHANGED_FILES" \
            --policy risk-policy.json \
            --output-format github-actions 2>&1

          # Capture outputs set by the script via $GITHUB_OUTPUT
          echo "Gate completed"

      - name: Post risk tier comment
        if: always()
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          TIER="${{ steps.gate.outputs.tier }}"
          TIER_EMOJI="ðŸŸ¡"
          if [ "$TIER" = "high" ]; then TIER_EMOJI="ðŸ”´"; fi
          if [ "$TIER" = "low" ]; then TIER_EMOJI="ðŸŸ¢"; fi

          gh pr comment "${{ github.event.pull_request.number }}" \
            --body "${TIER_EMOJI} **Risk tier: \`${TIER}\`**" \
            2>/dev/null || true

  # â”€â”€ Step 2: Run tests (high and medium risk only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  tests:
    name: "Test: Run Test Suite"
    needs: risk-gate
    if: |
      needs.risk-gate.outputs.blocked != 'true' &&
      (needs.risk-gate.outputs.tier == 'high' || needs.risk-gate.outputs.tier == 'medium')
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: app_test
        ports:
          - "5432:5432"
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      neo4j:
        image: neo4j:5.14
        env:
          NEO4J_AUTH: neo4j/testing123
          NEO4J_PLUGINS: '["apoc"]'
          NEO4J_dbms_security_procedures_unrestricted: apoc.*
        ports:
          - "7687:7687"
          - "7474:7474"
        options: >-
          --health-cmd "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"
          --health-interval 15s
          --health-timeout 10s
          --health-retries 10
          --health-start-period 30s

      redis:
        image: redis:7-alpine
        ports:
          - "6379:6379"
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/app_test
          NEO4J_URI: bolt://localhost:7687
          NEO4J_PASSWORD: testing123
          REDIS_URL: redis://localhost:6379
        run: |
          pytest \
            --maxfail=10 \
            --tb=short \
            --cov=apps \
            --cov-report=xml \
            --cov-report=term-missing \
            -q \
            2>&1

  # â”€â”€ Step 3: Claude correctness review â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  claude-review:
    name: "Review: Code Correctness"
    needs: [risk-gate, tests]
    # Run if not blocked, and tests passed (or were skipped for low-tier)
    if: |
      always() &&
      needs.risk-gate.outputs.blocked != 'true' &&
      (needs.tests.result == 'success' || needs.tests.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Generate GitHub App token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Claude code review
        id: review
        uses: anthropics/claude-code-action@v1
        env:
          ANTHROPIC_BASE_URL: ${{ secrets.ANTHROPIC_BASE_URL }}
          ANTHROPIC_AUTH_TOKEN: ${{ secrets.ANTHROPIC_API_KEY }}
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          settings: ${{ secrets.CLAUDE_SETTINGS }}
          github_token: ${{ steps.app-token.outputs.token }}
          allowed_bots: "agentfactory-bot[bot]"
          prompt: |
            Review this PR as a senior engineer familiar with this codebase.

            FIRST: Read CLAUDE.md â€” it defines all patterns you must enforce.
            THEN: Read ARCHITECTURE.md â€” understand the invariants.
            THEN: Review the diff of this PR.

            Focus on:
            1. **Architectural invariants** â€” violations of rules in ARCHITECTURE.md are BLOCKING
            2. **Security** â€” auth missing, tenant isolation missing, SQL/Cypher injection
            3. **Anti-patterns** â€” anything listed in CLAUDE.md as a BLOCKING violation
            4. **Test quality** â€” are tests meaningful, or do they just verify the implementation?
            5. **Error handling** â€” bare excepts, missing logging, swallowed errors

            Response format:
            - Start with one of: "âœ… LGTM â€” no blocking issues" or "ðŸš« BLOCKING ISSUES FOUND"
            - List each BLOCKING issue with file:line and explanation
            - List SUGGESTIONS separately (not blocking)
            - Be specific â€” explain why, not just what

            Risk tier for this PR: ${{ needs.risk-gate.outputs.tier }}

            If the risk tier is HIGH, be thorough. If LOW (docs only), be brief.
          claude_args: "--max-turns 15 --model ${{ vars.CLAUDE_OPUS_MODEL || 'claude-opus-4-6' }} --allowedTools 'Read,Glob,Grep'"

  # â”€â”€ Step 4: Spec coverage audit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Critical: separate from correctness review.
  # The correctness reviewer reads the implementation. This step reads ONLY the
  # ticket and test files â€” specifically to catch tautological tests that verify
  # the implementation rather than the specification.
  # See: https://news.ycombinator.com/item?id=... "AI made every test pass, but..."
  spec-audit:
    name: "Audit: Spec Coverage"
    needs: [risk-gate, tests]
    if: |
      always() &&
      needs.risk-gate.outputs.blocked != 'true' &&
      needs.risk-gate.outputs.tier != 'low' &&
      (needs.tests.result == 'success' || needs.tests.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Generate GitHub App token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Extract PR metadata
        id: meta
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          # Get the PR body (contains ClickUp task ID and description)
          PR_BODY=$(gh pr view "${{ github.event.pull_request.number }}" --json body -q .body)
          echo "pr_body<<EOF" >> "$GITHUB_OUTPUT"
          echo "$PR_BODY" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

      - name: Spec coverage audit
        uses: anthropics/claude-code-action@v1
        env:
          ANTHROPIC_BASE_URL: ${{ secrets.ANTHROPIC_BASE_URL }}
          ANTHROPIC_AUTH_TOKEN: ${{ secrets.ANTHROPIC_API_KEY }}
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          settings: ${{ secrets.CLAUDE_SETTINGS }}
          github_token: ${{ steps.app-token.outputs.token }}
          allowed_bots: "agentfactory-bot[bot]"
          prompt: |
            SPEC COVERAGE AUDIT â€” do NOT read any implementation files.

            You are auditing whether the tests verify the SPECIFICATION, not just
            the specific implementation that was written. This is different from
            code review â€” you must not read the implementation.

            The specification (what was asked for):
            ${{ steps.meta.outputs.pr_body }}

            Steps:
            1. List the changed test files in this PR (using git diff --name-only)
            2. Read ONLY the test files (not the implementation they test)
            3. For each test, answer: does this test verify observable behavior
               from the specification above, or does it only verify the specific
               code that was written?

            A tautological test: would still pass if the implementation was subtly
            wrong relative to the spec. Example: testing that a function returns
            the object it was given, rather than testing the transformation behavior.

            Post findings labeled [SPEC-AUDIT]:
            - [SPEC-AUDIT] BLOCKING: <description of tautological test>
            - [SPEC-AUDIT] MISSING: <spec requirement with no test coverage>
            - [SPEC-AUDIT] OK if all tests appear spec-driven

            Do not read implementation files. If you find yourself reading a
            non-test file, stop and only look at test files.
          claude_args: "--max-turns 15 --model ${{ vars.CLAUDE_OPUS_MODEL || 'claude-opus-4-6' }} --allowedTools 'Bash,Glob,Grep,Read'"

  # â”€â”€ Step 5: Callback to orchestrator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  notify-orchestrator:
    name: "Notify: Orchestrator"
    needs: [check-branch, risk-gate, tests, claude-review, spec-audit]
    if: always() && needs.check-branch.outputs.is_agent_pr == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Generate GitHub App token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          token: ${{ steps.app-token.outputs.token }}
          ref: main

      - name: Determine overall status
        id: status
        run: |
          GATE="${{ needs.risk-gate.result }}"
          TESTS="${{ needs.tests.result }}"
          REVIEW="${{ needs.claude-review.result }}"
          AUDIT="${{ needs.spec-audit.result }}"
          BLOCKED="${{ needs.risk-gate.outputs.blocked }}"

          if [ "$BLOCKED" = "true" ] || [ "$GATE" = "failure" ]; then
            echo "outcome=blocked" >> "$GITHUB_OUTPUT"
          elif [ "$TESTS" = "failure" ]; then
            echo "outcome=tests-failed" >> "$GITHUB_OUTPUT"
          elif [ "$REVIEW" = "failure" ] || [ "$AUDIT" = "failure" ]; then
            echo "outcome=review-failed" >> "$GITHUB_OUTPUT"
          else
            echo "outcome=clean" >> "$GITHUB_OUTPUT"
          fi

      - name: Mark PR ready for review
        if: steps.status.outputs.outcome == 'clean'
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          gh pr ready "${{ github.event.pull_request.number }}" \
            --repo "${{ github.repository }}" || echo "::warning::Failed to mark PR as ready"

      - name: Callback â€” review clean
        if: steps.status.outputs.outcome == 'clean'
        env:
          ORCHESTRATOR_URL: ${{ secrets.ORCHESTRATOR_URL }}
          CALLBACK_SECRET: ${{ secrets.CALLBACK_SECRET }}
        run: |
          # Orchestrator callback (optional â€” skipped if not configured)
          if [ -n "$ORCHESTRATOR_URL" ]; then
            curl --retry 3 \
              -X POST "${ORCHESTRATOR_URL}/callbacks/review-clean" \
              -H "Content-Type: application/json" \
              -H "X-Callback-Secret: ${CALLBACK_SECRET}" \
              -d "{
                \"pr_url\": \"${{ github.event.pull_request.html_url }}\",
                \"pr_number\": ${{ github.event.pull_request.number }},
                \"branch\": \"${{ github.head_ref }}\",
                \"risk_tier\": \"${{ needs.risk-gate.outputs.tier }}\",
                \"run_id\": \"${{ github.run_id }}\"
              }" \
              --fail-with-body || echo "::warning::Orchestrator callback failed"
          else
            echo "No ORCHESTRATOR_URL configured â€” skipping callback"
          fi

      # Post a summary comment directly on the PR (works with or without orchestrator)
      - name: PR comment â€” review clean
        if: steps.status.outputs.outcome == 'clean'
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          TIER="${{ needs.risk-gate.outputs.tier }}"
          TIER_EMOJI="ðŸŸ¡"
          if [ "$TIER" = "high" ]; then TIER_EMOJI="ðŸ”´"; fi
          if [ "$TIER" = "low" ]; then TIER_EMOJI="ðŸŸ¢"; fi

          BODY="âœ… **All automated checks passed**

          ${TIER_EMOJI} Risk tier: \`${TIER}\`
          â€¢ Risk policy gate: âœ…
          â€¢ Tests: âœ…
          â€¢ Code review: âœ…
          â€¢ Spec coverage audit: âœ…

          Ready for human review and merge."

          gh pr comment "${{ github.event.pull_request.number }}" \
            --repo "${{ github.repository }}" \
            --body "$BODY" || echo "::warning::Failed to post PR comment"

      - name: Callback â€” blocked
        if: steps.status.outputs.outcome != 'clean'
        env:
          ORCHESTRATOR_URL: ${{ secrets.ORCHESTRATOR_URL }}
          CALLBACK_SECRET: ${{ secrets.CALLBACK_SECRET }}
        run: |
          if [ -n "$ORCHESTRATOR_URL" ]; then
            curl --retry 3 \
              -X POST "${ORCHESTRATOR_URL}/callbacks/blocked" \
              -H "Content-Type: application/json" \
              -H "X-Callback-Secret: ${CALLBACK_SECRET}" \
              -d "{
                \"pr_url\": \"${{ github.event.pull_request.html_url }}\",
                \"pr_number\": ${{ github.event.pull_request.number }},
                \"branch\": \"${{ github.head_ref }}\",
                \"reason\": \"${{ steps.status.outputs.outcome }}\",
                \"run_id\": \"${{ github.run_id }}\"
              }" \
              --fail-with-body || echo "::warning::Orchestrator callback failed"
          else
            echo "No ORCHESTRATOR_URL configured â€” skipping callback"
          fi

      # â”€â”€ Outcome logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Append a structured record of this pipeline run to data/agent-outcomes.jsonl.
      # This is the foundation for self-improvement: we record what happened
      # so we can later extract patterns from successes and failures.
      - name: Log pipeline outcome
        if: always()
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          OUTCOME="${{ steps.status.outputs.outcome }}"
          PR_NUMBER="${{ github.event.pull_request.number }}"
          BRANCH="${{ github.head_ref }}"
          TIER="${{ needs.risk-gate.outputs.tier }}"

          # Get changed files
          CHANGED_FILES=$(git diff --name-only "origin/main...origin/${BRANCH}" 2>/dev/null \
            | jq -R -s -c 'split("\n") | map(select(. != ""))' || echo "[]")

          # Extract review findings from PR comments (bot comments containing BLOCKING or SPEC-AUDIT)
          REVIEW_FINDINGS=$(gh api "repos/${{ github.repository }}/issues/${PR_NUMBER}/comments" \
            --jq '[.[] | select(.user.login == "agentfactory-bot[bot]") | .body
                   | capture("(?:BLOCKING|\\[SPEC-AUDIT\\] BLOCKING|\\[SPEC-AUDIT\\] MISSING):? (?P<finding>[^\n]+)"; "g")
                   | .finding] | flatten | unique' 2>/dev/null || echo "[]")

          # Build the outcome record
          RECORD=$(jq -n \
            --arg outcome "$OUTCOME" \
            --arg pr_url "${{ github.event.pull_request.html_url }}" \
            --argjson pr_number "$PR_NUMBER" \
            --arg branch "$BRANCH" \
            --arg risk_tier "${TIER:-unknown}" \
            --arg gate "${{ needs.risk-gate.result }}" \
            --arg tests "${{ needs.tests.result }}" \
            --arg review "${{ needs.claude-review.result }}" \
            --arg audit "${{ needs.spec-audit.result }}" \
            --arg run_id "${{ github.run_id }}" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --argjson files_changed "$CHANGED_FILES" \
            --argjson review_findings "${REVIEW_FINDINGS:-[]}" \
            '{
              outcome: $outcome,
              pr_url: $pr_url,
              pr_number: $pr_number,
              branch: $branch,
              risk_tier: $risk_tier,
              checks: {
                gate: $gate,
                tests: $tests,
                review: $review,
                spec_audit: $audit
              },
              files_changed: $files_changed,
              review_findings: $review_findings,
              run_id: $run_id,
              timestamp: $timestamp
            }')

          # Append to outcome log
          mkdir -p data
          echo "$RECORD" >> data/agent-outcomes.jsonl

          # Commit the log update to main
          git config user.name "AgentFactory Bot"
          git config user.email "agent@agentfactory.dev"
          git add data/agent-outcomes.jsonl
          if ! git diff --staged --quiet; then
            git commit -m "data: log review outcome for PR #${PR_NUMBER} [${OUTCOME}]"
            git push origin main || echo "::warning::Failed to push outcome log"
          fi
